{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 4 Project - Real Estate Portfolio Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the data processing and analysis for the Flatiron School Data Science Bootcamp Mod 4 Project. Below we'll analyze a dataset comprised of Zillow data - zipcodes from around the U.S., and seek to answer the question: \n",
    "\n",
    "_\"What are the top 5 best zipcodes to invest in?_\n",
    "\n",
    "In this case we are acting as a consultant to a real estate investment firm, but otherwise are left to our own devices to determine how to qualify the term \"best\". We'll further state our business case and assumptions below, but we'll start by stating that \"best\" will be more complex than the fastest growing and most expensive properties. We'll seek to create a balanced portfolio of properties that match or exceed market returns, but are spread across value segments to diversify our holdings and thereby mitigate risk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin with importing the necessary libraries we'll need for our analysis and taking an initial look at our data\n",
    "\n",
    "- DESCRIBE DATA - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "#turning off warnings for final version to make notebook easier to read\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14723 entries, 0 to 14722\n",
      "Columns: 272 entries, RegionID to 2018-04\n",
      "dtypes: float64(219), int64(49), object(4)\n",
      "memory usage: 30.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>334200.0</td>\n",
       "      <td>335400.0</td>\n",
       "      <td>336500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1005500</td>\n",
       "      <td>1007500</td>\n",
       "      <td>1007800</td>\n",
       "      <td>1009600</td>\n",
       "      <td>1013300</td>\n",
       "      <td>1018700</td>\n",
       "      <td>1024400</td>\n",
       "      <td>1030700</td>\n",
       "      <td>1033800</td>\n",
       "      <td>1030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90668</td>\n",
       "      <td>75070</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>Collin</td>\n",
       "      <td>2</td>\n",
       "      <td>235700.0</td>\n",
       "      <td>236900.0</td>\n",
       "      <td>236700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>308000</td>\n",
       "      <td>310000</td>\n",
       "      <td>312500</td>\n",
       "      <td>314100</td>\n",
       "      <td>315000</td>\n",
       "      <td>316600</td>\n",
       "      <td>318100</td>\n",
       "      <td>319600</td>\n",
       "      <td>321100</td>\n",
       "      <td>321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>3</td>\n",
       "      <td>210400.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321000</td>\n",
       "      <td>320600</td>\n",
       "      <td>320200</td>\n",
       "      <td>320400</td>\n",
       "      <td>320800</td>\n",
       "      <td>321200</td>\n",
       "      <td>321200</td>\n",
       "      <td>323000</td>\n",
       "      <td>326900</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>498100.0</td>\n",
       "      <td>500900.0</td>\n",
       "      <td>503100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1289800</td>\n",
       "      <td>1287700</td>\n",
       "      <td>1287400</td>\n",
       "      <td>1291500</td>\n",
       "      <td>1296600</td>\n",
       "      <td>1299000</td>\n",
       "      <td>1302700</td>\n",
       "      <td>1306400</td>\n",
       "      <td>1308500</td>\n",
       "      <td>1307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93144</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>5</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119100</td>\n",
       "      <td>119400</td>\n",
       "      <td>120000</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120500</td>\n",
       "      <td>121000</td>\n",
       "      <td>121500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  RegionName      City State              Metro CountyName  \\\n",
       "0     84654       60657   Chicago    IL            Chicago       Cook   \n",
       "1     90668       75070  McKinney    TX  Dallas-Fort Worth     Collin   \n",
       "2     91982       77494      Katy    TX            Houston     Harris   \n",
       "3     84616       60614   Chicago    IL            Chicago       Cook   \n",
       "4     93144       79936   El Paso    TX            El Paso    El Paso   \n",
       "\n",
       "   SizeRank   1996-04   1996-05   1996-06   ...     2017-07  2017-08  2017-09  \\\n",
       "0         1  334200.0  335400.0  336500.0   ...     1005500  1007500  1007800   \n",
       "1         2  235700.0  236900.0  236700.0   ...      308000   310000   312500   \n",
       "2         3  210400.0  212200.0  212200.0   ...      321000   320600   320200   \n",
       "3         4  498100.0  500900.0  503100.0   ...     1289800  1287700  1287400   \n",
       "4         5   77300.0   77300.0   77300.0   ...      119100   119400   120000   \n",
       "\n",
       "   2017-10  2017-11  2017-12  2018-01  2018-02  2018-03  2018-04  \n",
       "0  1009600  1013300  1018700  1024400  1030700  1033800  1030600  \n",
       "1   314100   315000   316600   318100   319600   321100   321800  \n",
       "2   320400   320800   321200   321200   323000   326900   329900  \n",
       "3  1291500  1296600  1299000  1302700  1306400  1308500  1307000  \n",
       "4   120300   120300   120300   120300   120500   121000   121500  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import zillow data and check info and first 5 lines\n",
    "df = pd.read_csv('zillow_data.csv')\n",
    "display(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that: \n",
    "* Our data has 14,723 rows and 272 columns\n",
    "* Most of the data is integers(49 columns) and floats (219 columns)\n",
    "* There are two identifiers for each row, 'RegionID' and 'RegionName'\n",
    "    * We'll look to see if they are unique, and also see which one is actually the zipcode\n",
    "    \n",
    "Let's count the number of unique values for our first six columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionID      14723\n",
       "RegionName    14723\n",
       "City           7554\n",
       "State            51\n",
       "Metro           701\n",
       "CountyName     1212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of unique values for the first 6 columns\n",
    "df.nunique()[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that RegionID and RegionName are both entirely unique. I little in depth analysis (looking up my own zipcode) tells us that RegionName is the column that represents zipcodes. We can drop RegionID in the next section. \n",
    "\n",
    "Otherwise it appear that we have all 50 states plus DC represented and a large number of cities and metro areas represented. Later in our analysis we'll take some of this into account to see if there are geographic considerations we can take into account when choosing zipcodes for our portfolio.\n",
    "\n",
    "Before we start processing our date let's also check for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metro      1043\n",
       "1996-04    1039\n",
       "1996-05    1039\n",
       "1996-06    1039\n",
       "1996-07    1039\n",
       "1996-08    1039\n",
       "1996-09    1039\n",
       "1996-10    1039\n",
       "1996-11    1039\n",
       "1996-12    1039\n",
       "1997-01    1039\n",
       "1997-02    1039\n",
       "1997-03    1039\n",
       "1997-04    1039\n",
       "1997-05    1039\n",
       "1997-06    1039\n",
       "1997-07    1038\n",
       "1997-08    1038\n",
       "1997-09    1038\n",
       "1997-10    1038\n",
       "1997-11    1038\n",
       "1997-12    1038\n",
       "1998-01    1036\n",
       "1998-02    1036\n",
       "1998-03    1036\n",
       "1998-04    1036\n",
       "1998-05    1036\n",
       "1998-06    1036\n",
       "1998-07    1036\n",
       "1998-08    1036\n",
       "           ... \n",
       "2012-01     224\n",
       "2012-02     224\n",
       "2012-03     224\n",
       "2012-04     224\n",
       "2012-05     224\n",
       "2012-06     224\n",
       "2012-07     206\n",
       "2012-08     206\n",
       "2012-09     206\n",
       "2012-10     206\n",
       "2012-11     206\n",
       "2012-12     206\n",
       "2013-01     151\n",
       "2013-02     151\n",
       "2013-03     151\n",
       "2013-04     151\n",
       "2013-05     151\n",
       "2013-06     151\n",
       "2013-07     109\n",
       "2013-08     109\n",
       "2013-09     109\n",
       "2013-10     109\n",
       "2013-11     109\n",
       "2013-12     109\n",
       "2014-01      56\n",
       "2014-02      56\n",
       "2014-03      56\n",
       "2014-04      56\n",
       "2014-05      56\n",
       "2014-06      56\n",
       "Length: 220, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns for null values and count them\n",
    "null_columns = df.columns[df.isnull().any()]\n",
    "df[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of missing values! \n",
    "* 220 columns are missing data\n",
    "* 1,043 rows do not have a value for 'Metro' \n",
    "* Many values in the 1990's are missing\n",
    "\n",
    "We'll address this in the next section while we're processing our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will process our data and begin to prepare it for analysis. We will fist deal with missing values. Next, we'll select data that meets the requirements of our business case and create segments for analysis. From there we'll move into exploratory analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Metro Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we saw that there are 1,043 missing values for 'Metro'. Let's take a closer look and Metro and City to see if there is a relationship we can use to impute some vales for what is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McKinney</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Katy</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Houston</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Katy</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>The Villages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nashville</td>\n",
       "      <td>Nashville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             City              Metro\n",
       "0         Chicago            Chicago\n",
       "1        McKinney  Dallas-Fort Worth\n",
       "2            Katy            Houston\n",
       "3         Chicago            Chicago\n",
       "4         El Paso            El Paso\n",
       "5         Houston            Houston\n",
       "6        New York           New York\n",
       "7         Chicago            Chicago\n",
       "8            Katy            Houston\n",
       "9   San Francisco      San Francisco\n",
       "10       New York           New York\n",
       "11   The Villages       The Villages\n",
       "12       New York           New York\n",
       "13       New York           New York\n",
       "14      Nashville          Nashville"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 15 combinations of 'City' and 'Metro'\n",
    "df[['City', 'Metro']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of 'Metro' values that are also a 'City' value\n",
    "df[df['Metro'] == df['City']].any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** 272 of the 701 values for Metro are also the name of city. It appears that replacing the Metro NaNs with the matching city name may be an effective way to impute those values. \n",
    "\n",
    "Let's take a quick look at our \"Metro\" values first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\bTop 10 Metros:\n",
      " New York                          779\n",
      "Los Angeles-Long Beach-Anaheim    347\n",
      "Chicago                           325\n",
      "Philadelphia                      281\n",
      "Washington                        249\n",
      "Boston                            246\n",
      "Dallas-Fort Worth                 217\n",
      "Minneapolis-St Paul               201\n",
      "Houston                           187\n",
      "Pittsburgh                        177\n",
      "Name: Metro, dtype: int64\n",
      "------------------------------\n",
      "Bottom 10 Metros:\n",
      " Poplar Bluff    1\n",
      "Borger          1\n",
      "Lamesa          1\n",
      "Espanola        1\n",
      "Yankton         1\n",
      "New Ulm         1\n",
      "Alamogordo      1\n",
      "Vicksburg       1\n",
      "Dodge City      1\n",
      "Wahpeton        1\n",
      "Name: Metro, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at the first 10 and last 10 value counts for 'Metro'\n",
    "print('\\bTop 10 Metros:\\n', df.Metro.value_counts()[:10])\n",
    "print('-----'*6)\n",
    "print('Bottom 10 Metros:\\n', df.Metro.value_counts()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace 'Metro' NaNs with the corresponding 'City' value\n",
    "df.Metro = df.Metro.fillna(value=df['City'])\n",
    "\n",
    "# check to see if any Metro NaNs remain \n",
    "df.Metro.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we've effectively replaced the Metro NaNs. Lets look at the top and bottom values again to see if anything has changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\bTop 10 Metros:\n",
      " New York                          779\n",
      "Los Angeles-Long Beach-Anaheim    347\n",
      "Chicago                           325\n",
      "Philadelphia                      282\n",
      "Washington                        249\n",
      "Boston                            246\n",
      "Dallas-Fort Worth                 217\n",
      "Minneapolis-St Paul               201\n",
      "Houston                           188\n",
      "Pittsburgh                        177\n",
      "Name: Metro, dtype: int64\n",
      "------------------------------\n",
      "Bottom 10 Metros:\n",
      " Post                   1\n",
      "Jena                   1\n",
      "Woodville              1\n",
      "Collins                1\n",
      "Mount Crested Butte    1\n",
      "Forest                 1\n",
      "Graham                 1\n",
      "Fort Jones             1\n",
      "Summerfield            1\n",
      "Petoskey               1\n",
      "Name: Metro, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at the first 10 and last 10 value counts for 'Metro'\n",
    "print('\\bTop 10 Metros:\\n', df.Metro.value_counts()[:10])\n",
    "print('-----'*6)\n",
    "print('Bottom 10 Metros:\\n', df.Metro.value_counts()[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 values are mostly the same. The Bottom 10 have changed completely, but it appears that there were already a significant number of Metro values that only occured once, so this shouldn't affect our analysis too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Price Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll consider a number of factors when dealing with price data:\n",
    "* Considering the housing market crash of 2008, our data includes both a period of abnormal growth (pre-2008), and a precipitous fall (2008-2009)\n",
    "* An ARIMA model requires at least 100 values to be accurate\n",
    "    * cite: What should be the minimum number of observations for a time series model?\n",
    "    * https://www.researchgate.net/post/What_should_be_the_minimum_number_of_observations_for_a_time_series_model\n",
    "    * Box, G. E. P., and G. C. Tiao. 1975. Intervention analysis with applications to economic and environmental problems. Journal of the American Statistical Association 70: 70{79.\n",
    "* As data for many years prior to 2008 is missing in over 1000 rows, and imputing that data would be very difficult, we'll instead drop all columns before 2009. This will still leave us with **112 values for our model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping 1996-2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1996-04', '1996-05', '1996-06', '1996-07', '1996-08', '1996-09',\n",
       "       '1996-10', '1996-11', '1996-12', '1997-01',\n",
       "       ...\n",
       "       '2008-03', '2008-04', '2008-05', '2008-06', '2008-07', '2008-08',\n",
       "       '2008-09', '2008-10', '2008-11', '2008-12'],\n",
       "      dtype='object', length=153)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a variable for column names between '1996-04' and '2008-12'\n",
    "drop_cols = df.columns[7:160]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14723 entries, 0 to 14722\n",
      "Columns: 119 entries, RegionID to 2018-04\n",
      "dtypes: float64(66), int64(49), object(4)\n",
      "memory usage: 13.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>2009-01</th>\n",
       "      <th>2009-02</th>\n",
       "      <th>2009-03</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>818300.0</td>\n",
       "      <td>814600.0</td>\n",
       "      <td>809800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1005500</td>\n",
       "      <td>1007500</td>\n",
       "      <td>1007800</td>\n",
       "      <td>1009600</td>\n",
       "      <td>1013300</td>\n",
       "      <td>1018700</td>\n",
       "      <td>1024400</td>\n",
       "      <td>1030700</td>\n",
       "      <td>1033800</td>\n",
       "      <td>1030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90668</td>\n",
       "      <td>75070</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>Collin</td>\n",
       "      <td>2</td>\n",
       "      <td>202400.0</td>\n",
       "      <td>201700.0</td>\n",
       "      <td>201200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>308000</td>\n",
       "      <td>310000</td>\n",
       "      <td>312500</td>\n",
       "      <td>314100</td>\n",
       "      <td>315000</td>\n",
       "      <td>316600</td>\n",
       "      <td>318100</td>\n",
       "      <td>319600</td>\n",
       "      <td>321100</td>\n",
       "      <td>321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>3</td>\n",
       "      <td>246700.0</td>\n",
       "      <td>246100.0</td>\n",
       "      <td>245800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321000</td>\n",
       "      <td>320600</td>\n",
       "      <td>320200</td>\n",
       "      <td>320400</td>\n",
       "      <td>320800</td>\n",
       "      <td>321200</td>\n",
       "      <td>321200</td>\n",
       "      <td>323000</td>\n",
       "      <td>326900</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>1065400.0</td>\n",
       "      <td>1057800.0</td>\n",
       "      <td>1048900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1289800</td>\n",
       "      <td>1287700</td>\n",
       "      <td>1287400</td>\n",
       "      <td>1291500</td>\n",
       "      <td>1296600</td>\n",
       "      <td>1299000</td>\n",
       "      <td>1302700</td>\n",
       "      <td>1306400</td>\n",
       "      <td>1308500</td>\n",
       "      <td>1307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93144</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>5</td>\n",
       "      <td>121600.0</td>\n",
       "      <td>121200.0</td>\n",
       "      <td>120700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119100</td>\n",
       "      <td>119400</td>\n",
       "      <td>120000</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120500</td>\n",
       "      <td>121000</td>\n",
       "      <td>121500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  RegionName      City State              Metro CountyName  \\\n",
       "0     84654       60657   Chicago    IL            Chicago       Cook   \n",
       "1     90668       75070  McKinney    TX  Dallas-Fort Worth     Collin   \n",
       "2     91982       77494      Katy    TX            Houston     Harris   \n",
       "3     84616       60614   Chicago    IL            Chicago       Cook   \n",
       "4     93144       79936   El Paso    TX            El Paso    El Paso   \n",
       "\n",
       "   SizeRank    2009-01    2009-02    2009-03   ...     2017-07  2017-08  \\\n",
       "0         1   818300.0   814600.0   809800.0   ...     1005500  1007500   \n",
       "1         2   202400.0   201700.0   201200.0   ...      308000   310000   \n",
       "2         3   246700.0   246100.0   245800.0   ...      321000   320600   \n",
       "3         4  1065400.0  1057800.0  1048900.0   ...     1289800  1287700   \n",
       "4         5   121600.0   121200.0   120700.0   ...      119100   119400   \n",
       "\n",
       "   2017-09  2017-10  2017-11  2017-12  2018-01  2018-02  2018-03  2018-04  \n",
       "0  1007800  1009600  1013300  1018700  1024400  1030700  1033800  1030600  \n",
       "1   312500   314100   315000   316600   318100   319600   321100   321800  \n",
       "2   320200   320400   320800   321200   321200   323000   326900   329900  \n",
       "3  1287400  1291500  1296600  1299000  1302700  1306400  1308500  1307000  \n",
       "4   120000   120300   120300   120300   120300   120500   121000   121500  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataframe with only values from 2009-01 onward\n",
    "df_2009 = df.drop(columns=drop_cols).copy()\n",
    "display(df_2009.info())\n",
    "df_2009.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
